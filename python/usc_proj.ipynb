{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dookda/cmu_py499/blob/main/gee_meji_usc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRz1pELnO2ey"
      },
      "outputs": [],
      "source": [
        "!pip install earthengine-api\n",
        "!pip install geemap folium\n",
        "\n",
        "# Authenticate and initialize the Earth Engine API\n",
        "import ee\n",
        "\n",
        "# Provide your Google Cloud project ID\n",
        "project_id = 'earthengine-380405'\n",
        "\n",
        "# Authenticate and initialize the Earth Engine API with the project ID\n",
        "ee.Authenticate()\n",
        "ee.Initialize(project=project_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "euIkQQ88kMZc",
        "outputId": "2c6dec85-b088-4cdc-c7aa-c07350740580"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "h7OiQ8Lz1PvM",
        "outputId": "eb0d09db-c466-47f5-a573-a1582d9c82f1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!rm -r '/content/drive/MyDrive/_DATASET/meji_usc.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "ewL64R3dpv0k",
        "outputId": "9293baba-6eca-4b24-88fa-d149ca0d3826"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "                    \n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "                \n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "                    \n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import ee\n",
        "import folium\n",
        "import geemap\n",
        "\n",
        "ee.Initialize()\n",
        "\n",
        "# hex150 = ee.FeatureCollection(\"projects/earthengine-380405/assets/hex150tb_4326\");\n",
        "hexpolygon = ee.FeatureCollection(\"projects/ee-sakda/assets/hex_usc\");\n",
        "site = hexpolygon.geometry().bounds()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "a_8R9Jm6qGc2",
        "outputId": "6d28004a-6094-4503-b64f-79e877fb0ef6"
      },
      "outputs": [],
      "source": [
        "import ee\n",
        "import folium\n",
        "import geemap\n",
        "import os\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def get_min(img, geom):\n",
        "    min_val = img.reduceRegion(\n",
        "        reducer=ee.Reducer.min(),\n",
        "        geometry=geom,\n",
        "        scale=100,\n",
        "        maxPixels=1e9\n",
        "    ).getInfo()\n",
        "    return min_val['constant']\n",
        "\n",
        "def get_max(img, geom):\n",
        "    max_val = img.reduceRegion(\n",
        "        reducer=ee.Reducer.max(),\n",
        "        geometry=geom,\n",
        "        scale=100,\n",
        "        maxPixels=1e9\n",
        "    ).getInfo()\n",
        "    return max_val['constant']\n",
        "\n",
        "def rename_property(feature, params):\n",
        "    mean_value = feature.get('mean')\n",
        "    feature = feature.set(params, mean_value)\n",
        "    feature = feature.set('mean', None)\n",
        "    return feature\n",
        "\n",
        "def set_default(feature, params):\n",
        "    value = ee.Number(feature.get(params))\n",
        "    return feature.set(params, ee.Algorithms.If(value, value, 0))\n",
        "\n",
        "def zonal_stat(image, geom, params):\n",
        "    z_stats = image.reduceRegions(\n",
        "        collection=geom,\n",
        "        reducer=ee.Reducer.mean(),\n",
        "        scale=100,\n",
        "        tileScale=1,\n",
        "        crs='EPSG:4326'\n",
        "    )\n",
        "    feat = z_stats.map(lambda feature: rename_property(feature, params))\n",
        "    feat = feat.map(lambda feature: set_default(feature, params))\n",
        "    return feat\n",
        "\n",
        "def kelvin_to_celsius(img):\n",
        "    return img.multiply(0.02).subtract(273.15).rename('LST_Celsius')\n",
        "\n",
        "def prepare_data(image):\n",
        "    proj = image.reproject(\n",
        "        crs=\"EPSG:32647\",\n",
        "        scale=100\n",
        "    )\n",
        "    clip_img = proj.clip(site)\n",
        "    return clip_img\n",
        "\n",
        "def show_scatter_plot(feat, params):\n",
        "    scatter_plot = geemap.ee_chart_by_feature(\n",
        "        ee.FeatureCollection(feat), x_property=params, y_properties=['usc'], chart_type='ScatterChart',\n",
        "        options={\n",
        "            'title': 'Scatter Plot of ' + params + ' vs usc',\n",
        "            'hAxis': {'title': params},\n",
        "            'vAxis': {'title': 'usc'},\n",
        "            'pointSize': 5\n",
        "        }\n",
        "    )\n",
        "    scatter_plot.show()\n",
        "\n",
        "def loadCollection(start_date, end_date):\n",
        "    O3 = ee.ImageCollection(\"COPERNICUS/S5P/OFFL/L3_O3\") \\\n",
        "        .filterBounds(site) \\\n",
        "        .filterDate(start_date, end_date) \\\n",
        "        .select('O3_column_number_density') \\\n",
        "        .map(prepare_data) \\\n",
        "        .median()\n",
        "\n",
        "    SO2 = ee.ImageCollection(\"COPERNICUS/S5P/OFFL/L3_SO2\") \\\n",
        "        .filterBounds(site) \\\n",
        "        .filterDate(start_date, end_date) \\\n",
        "        .select('SO2_column_number_density') \\\n",
        "        .map(prepare_data) \\\n",
        "        .median()\n",
        "\n",
        "    AER_LH = ee.ImageCollection(\"COPERNICUS/S5P/OFFL/L3_AER_LH\") \\\n",
        "        .filterBounds(site) \\\n",
        "        .filterDate(start_date, end_date) \\\n",
        "        .select('aerosol_optical_depth') \\\n",
        "        .map(prepare_data) \\\n",
        "        .median()\n",
        "\n",
        "    CH4 = ee.ImageCollection(\"COPERNICUS/S5P/OFFL/L3_CH4\") \\\n",
        "        .filterBounds(site) \\\n",
        "        .filterDate(start_date, end_date) \\\n",
        "        .select('CH4_column_volume_mixing_ratio_dry_air') \\\n",
        "        .map(prepare_data) \\\n",
        "        .median()\n",
        "\n",
        "    HCHO = ee.ImageCollection(\"COPERNICUS/S5P/OFFL/L3_HCHO\") \\\n",
        "        .filterBounds(site) \\\n",
        "        .filterDate(start_date, end_date) \\\n",
        "        .select('tropospheric_HCHO_column_number_density') \\\n",
        "        .map(prepare_data) \\\n",
        "        .median()\n",
        "\n",
        "    NO2 = ee.ImageCollection(\"COPERNICUS/S5P/OFFL/L3_NO2\") \\\n",
        "        .filterBounds(site) \\\n",
        "        .filterDate(start_date, end_date) \\\n",
        "        .select('NO2_column_number_density') \\\n",
        "        .map(prepare_data) \\\n",
        "        .median()\n",
        "\n",
        "    CO = ee.ImageCollection(\"COPERNICUS/S5P/OFFL/L3_CO\") \\\n",
        "        .filterBounds(site) \\\n",
        "        .filterDate(start_date, end_date) \\\n",
        "        .select('CO_column_number_density') \\\n",
        "        .map(prepare_data) \\\n",
        "        .median()\n",
        "    # https://pro.arcgis.com/en/pro-app/latest/arcpy/spatial-analyst/an-overview-of-the-spatial-analyst-functions.htm\n",
        "\n",
        "    \n",
        "    # NDVI = ((NIR - Red) / (NIR + Red))\n",
        "    # NDMI = (NIR - SWIR1)/(NIR + SWIR1)\n",
        "    # NDBI = (SWIR - NIR) / (SWIR + NIR)\n",
        "    # B12=SWIR2, B11=SWIR1, B8=NIR, B4=Red, B3=Green, B2=Blue\n",
        "\n",
        "    NDVI = ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\") \\\n",
        "        .filterBounds(site) \\\n",
        "        .filterDate(start_date, end_date) \\\n",
        "        .map(prepare_data) \\\n",
        "        .median() \\\n",
        "        .normalizedDifference([\"B8\", \"B4\"])\n",
        "    \n",
        "    NDBI = ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\") \\\n",
        "        .filterBounds(site) \\\n",
        "        .filterDate(start_date, end_date) \\\n",
        "        .map(prepare_data) \\\n",
        "        .median() \\\n",
        "        .normalizedDifference([\"B12\", \"B8\"])\n",
        "    \n",
        "    NDMI = ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\") \\\n",
        "        .filterBounds(site) \\\n",
        "        .filterDate(start_date, end_date) \\\n",
        "        .map(prepare_data) \\\n",
        "        .median() \\\n",
        "        .normalizedDifference([\"B8\", \"B11\"])\n",
        "\n",
        "    LST = ee.ImageCollection(\"MODIS/061/MOD11A1\") \\\n",
        "        .filterBounds(site) \\\n",
        "        .filterDate(start_date, end_date) \\\n",
        "        .select('LST_Day_1km') \\\n",
        "        .map(prepare_data) \\\n",
        "        .map(kelvin_to_celsius) \\\n",
        "        .median()\n",
        "    return O3, SO2, AER_LH, CH4, HCHO, NO2, CO, NDVI, NDBI, NDMI, LST\n",
        "\n",
        "# get week from date\n",
        "def get_week(date= '2021-01-01'):\n",
        "    date = ee.Date(date)\n",
        "    return date.get('week')\n",
        "\n",
        "# get date range from week\n",
        "def get_date_range(week=1, year=2021):\n",
        "    start_date = ee.Date.fromYMD(year, 1, 1)\n",
        "    start_date = start_date.advance(week, 'week')\n",
        "    end_date = start_date.advance(1, 'week')\n",
        "    return start_date, end_date\n",
        "\n",
        "def export_img_to_drive(image, name, folder, scale=100):\n",
        "    task = ee.batch.Export.image.toDrive(\n",
        "        image=image,\n",
        "        description=name,\n",
        "        folder=folder,\n",
        "        fileNamePrefix=name,\n",
        "        scale=scale,\n",
        "        region=site\n",
        "    )\n",
        "    task.start()\n",
        "\n",
        "def export_csv_to_drive(feature_collection, param_name, folder):\n",
        "    task = ee.batch.Export.table.toDrive(\n",
        "        collection=feature_collection,\n",
        "        description=param_name,\n",
        "        folder=folder,\n",
        "        fileNamePrefix=param_name,\n",
        "        fileFormat='CSV'\n",
        "    )\n",
        "    task.start()\n",
        "\n",
        "def corr_chart():\n",
        "    dir = '/Users/sakdahomhuan/Library/CloudStorage/GoogleDrive-sakda.homhuan@gmail.com/My Drive/'\n",
        "    listfile = os.path.join(dir, '_GEE')\n",
        "    for file in os.listdir(listfile):\n",
        "        df = pd.read_csv(os.path.join(listfile, file))\n",
        "        # print(df.head())\n",
        "        columns_of_interest = ['aer_lh', 'bd_h', 'ch4', 'co', 'hcho', 'lst',\n",
        "                        'no2', 'o3', 'road_w','so2', 'usc', 'ndvi']\n",
        "\n",
        "        correlation_matrix = df[columns_of_interest].corr()\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "        plt.title('Correlation Matrix')\n",
        "        # plt.show()\n",
        "\n",
        "        chart_name = file.replace('.csv', '.png')\n",
        "        print(chart_name)\n",
        "        output_dir = os.path.join(listfile, 'chart')\n",
        "        plt.savefig(os.path.join(output_dir, chart_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "week = range(1, 53)\n",
        "year = 2021\n",
        "\n",
        "for w in week:\n",
        "    try:\n",
        "        start_date, end_date = get_date_range(w, year)\n",
        "        print(w, start_date.format('YYYY-MM-dd').getInfo(), end_date.format('YYYY-MM-dd').getInfo())\n",
        "\n",
        "        O3, SO2, AER_LH, CH4, HCHO, NO2, CO, NDVI, NDBI, NDMI, LST = loadCollection(start_date, end_date)\n",
        "\n",
        "        lst = zonal_stat(LST, hexpolygon, 'lst')\n",
        "        ndvi = zonal_stat(NDVI, lst, 'ndvi')\n",
        "        o3 = zonal_stat(O3, ndvi, 'o3')\n",
        "        so2 = zonal_stat(SO2, o3, 'so2')\n",
        "        aer_lh = zonal_stat(AER_LH, so2, 'aer_lh')\n",
        "        ch4 = zonal_stat(CH4, aer_lh, 'ch4')\n",
        "        hcho = zonal_stat(HCHO, ch4, 'hcho')\n",
        "        co = zonal_stat(CO, hcho, 'co')\n",
        "        ndbi = zonal_stat(NDBI, co, 'ndbi')\n",
        "        ndmi = zonal_stat(NDMI, ndbi, 'ndmi')\n",
        "        no2 = zonal_stat(NO2, ndmi, 'no2')\n",
        "\n",
        "        export_csv_to_drive(feature_collection=no2, param_name='usc_'+str(w)+'_'+str(year), folder='_GEE')\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred in week {w}: {e}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "dir = 'G:/My Drive'\n",
        "listfile = os.path.join(dir, 'usc_zonal_cir_1')\n",
        "print(listfile)\n",
        "\n",
        "\n",
        "for f in os.listdir(listfile):\n",
        "    print(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "dir = 'G:/My Drive/'\n",
        "listfile = os.path.join(dir, 'usc_zonal_cir_1')\n",
        "print(listfile)\n",
        "for file in os.listdir(listfile):\n",
        "    if not file.endswith('.csv'):\n",
        "        continue\n",
        "\n",
        "    df = pd.read_csv(os.path.join(listfile, file))\n",
        "    # columns_of_interest = ['usc', 'co', 'no2', 'o3', 'so2', 'lst', 'ndbi', 'ndmi','ndvi']\n",
        "    columns_of_interest = ['usc', 'lst', 'ndbi', 'ndmi','ndvi']\n",
        "    # print(df.head())\n",
        "    # print(df[columns_of_interest].head())\n",
        "\n",
        "    f_name = file.split('.')\n",
        "    correlation_matrix = df[columns_of_interest].corr()\n",
        "\n",
        "    # print(correlation_matrix)\n",
        "\n",
        "    usc_record = correlation_matrix[:1]\n",
        "    usc_record['file_name'] = f_name[0]\n",
        "    csv_path = os.path.join(listfile, 'correlation_data.txt')\n",
        "    if os.path.exists(csv_path):\n",
        "        usc_record.to_csv(csv_path, mode='a', header=False, index=False)\n",
        "    else:\n",
        "        usc_record.to_csv(csv_path, index=False)\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "    plt.title('Correlation Matrix ' + str(f_name[0]))\n",
        "    # plt.show()\n",
        "\n",
        "    output_dir = os.path.join(listfile, 'chart')\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "    \n",
        "    chart_name = f_name[0] + '.png'\n",
        "    chart_path = os.path.join(output_dir, chart_name)\n",
        "\n",
        "    if os.path.exists(chart_path):\n",
        "        os.remove(chart_path)\n",
        "    plt.savefig(chart_path)\n",
        "    # plt.close()\n",
        "\n",
        "    print('saved ' + chart_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "qzpTHo8QqJ0v",
        "outputId": "5394be2b-ee8e-44fe-a8e5-f0ee7869ed24"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'loadCollection' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[3], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m start_date \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2024-01-01\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m end_date \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2024-01-31\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 5\u001b[0m O3, SO2, AER_LH, CH4, HCHO, NO2, CO, NDVI, NDBI, NDMI, LST \u001b[38;5;241m=\u001b[39m \u001b[43mloadCollection\u001b[49m(start_date, end_date)\n\u001b[0;32m      7\u001b[0m lst \u001b[38;5;241m=\u001b[39m zonal_stat(LST, hexpolygon, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlst\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m ndvi \u001b[38;5;241m=\u001b[39m zonal_stat(NDVI, lst, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mndvi\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'loadCollection' is not defined"
          ]
        }
      ],
      "source": [
        "# Dependence layer\n",
        "start_date = '2024-01-01'\n",
        "end_date = '2024-01-31'\n",
        "\n",
        "O3, SO2, AER_LH, CH4, HCHO, NO2, CO, NDVI, NDBI, NDMI, LST = loadCollection(start_date, end_date)\n",
        "\n",
        "lst = zonal_stat(LST, hexpolygon, 'lst')\n",
        "ndvi = zonal_stat(NDVI, lst, 'ndvi')\n",
        "o3 = zonal_stat(O3, ndvi, 'o3')\n",
        "so2 = zonal_stat(SO2, o3, 'so2')\n",
        "aer_lh = zonal_stat(AER_LH, so2, 'aer_lh')\n",
        "ch4 = zonal_stat(CH4, aer_lh, 'ch4')\n",
        "hcho = zonal_stat(HCHO, ch4, 'hcho')\n",
        "co = zonal_stat(CO, hcho, 'co')\n",
        "ndbi = zonal_stat(NDBI, co, 'ndbi')\n",
        "ndmi = zonal_stat(NDMI, ndbi, 'ndmi')\n",
        "no2 = zonal_stat(NO2, ndmi, 'no2')\n",
        "\n",
        "# Create map\n",
        "map_center = [18.80, 99]\n",
        "f = folium.Figure(height=400)\n",
        "m = folium.Map(location=map_center, zoom_start=12).add_to(f)\n",
        "\n",
        "google_satellite = folium.TileLayer(\n",
        "    tiles='https://mt1.google.com/vt/lyrs=s&x={x}&y={y}&z={z}',\n",
        "    attr='Google',\n",
        "    name='Google Satellite',\n",
        "    overlay=False,\n",
        "    control=True\n",
        ").add_to(m)\n",
        "\n",
        "def showMap(feat, geom, param):\n",
        "  empty = ee.Image().byte()\n",
        "  imageUsc = empty.paint( featureCollection=feat, color=param)\n",
        "  visualization = {\n",
        "      'min': get_min(imageUsc, geom),\n",
        "      'max': get_max(imageUsc, geom),\n",
        "      'palette': ['green', 'yellow', 'red']\n",
        "  }\n",
        "\n",
        "  map_id_dict = ee.Image(imageUsc).getMapId(visualization)\n",
        "  folium.TileLayer(\n",
        "      tiles=map_id_dict['tile_fetcher'].url_format,\n",
        "      attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "      name=param,\n",
        "      overlay=True,\n",
        "      control=True,\n",
        "      opacity=0.5\n",
        "  ).add_to(m)\n",
        "\n",
        "showMap(co, site, 'usc')\n",
        "showMap(no2, site, 'no2')\n",
        "showMap(ndvi, site, 'ndvi')\n",
        "showMap(ndmi, site, 'ndmi')\n",
        "showMap(ndbi, site, 'ndbi')\n",
        "showMap(lst, site, 'lst')\n",
        "showMap(o3, site, 'o3')\n",
        "\n",
        "folium.LayerControl().add_to(m)\n",
        "m\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "nIQHueAOxaWJ",
        "outputId": "d9bd9828-ca0a-4120-8ff9-0c82704232dc"
      },
      "outputs": [],
      "source": [
        "# Export to Drive\n",
        "export_task = ee.batch.Export.table.toDrive(\n",
        "    collection=no2,\n",
        "    description='zonal_statistics',\n",
        "    folder='_DATASET',\n",
        "    fileNamePrefix='meji_usc2',\n",
        "    fileFormat='CSV'\n",
        ")\n",
        "export_task.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6cKsWnkDoWnt",
        "outputId": "9c6bb490-7b6f-4a86-dd30-816aefab3382"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "file_path = '/content/drive/MyDrive/_DATASET/meji_usc.csv'\n",
        "\n",
        "df = pd.read_csv(file_path)\n",
        "print(df.columns)\n",
        "\n",
        "columns_of_interest = ['aer_lh', 'bd_h', 'ch4', 'co', 'hcho', 'lst',\n",
        "                       'no2', 'o3', 'road_w','so2', 'usc', 'ndvi']\n",
        "\n",
        "correlation_matrix = df[columns_of_interest].corr()\n",
        "print(correlation_matrix)\n",
        "# Plot the correlation matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "id": "n059EC-V6Lch",
        "outputId": "e9d91d12-cfdd-45c8-c288-f509a651a4ef"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Mount Google Drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "file_path = '/content/drive/MyDrive/_DATASET/meji_usc.csv'\n",
        "\n",
        "df = pd.read_csv(file_path)\n",
        "df = df.dropna(subset=['usc'])\n",
        "\n",
        "if df.shape[0] == 0:\n",
        "    raise ValueError(\"No samples available after dropping rows with null values.\")\n",
        "\n",
        "target_variable = 'co'\n",
        "columns_of_interest = ['usc', 'ndvi', 'lst']\n",
        "\n",
        "X = df[columns_of_interest]\n",
        "y = df[target_variable]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Forward stepwise regression\n",
        "def forward_stepwise_selection(X, y):\n",
        "    initial_features = []\n",
        "    remaining_features = list(X.columns)\n",
        "    best_features = []\n",
        "    while remaining_features:\n",
        "        scores_with_candidates = []\n",
        "        for candidate in remaining_features:\n",
        "            features = initial_features + [candidate]\n",
        "            X_train_with_candidate = sm.add_constant(X[features])\n",
        "            model = sm.OLS(y, X_train_with_candidate).fit()\n",
        "            score = model.rsquared_adj\n",
        "            scores_with_candidates.append((score, candidate))\n",
        "        scores_with_candidates.sort(reverse=True)\n",
        "        best_new_score, best_candidate = scores_with_candidates[0]\n",
        "        if initial_features:\n",
        "            best_old_score = sm.OLS(y, sm.add_constant(X[initial_features])).fit().rsquared_adj\n",
        "            if best_new_score <= best_old_score:\n",
        "                break\n",
        "        initial_features.append(best_candidate)\n",
        "        remaining_features.remove(best_candidate)\n",
        "        best_features.append((best_new_score, best_candidate))\n",
        "    return best_features\n",
        "\n",
        "# Perform forward stepwise selection\n",
        "best_features = forward_stepwise_selection(X_train, y_train)\n",
        "\n",
        "# Print the selected features and their scores\n",
        "print(\"Selected features and their adjusted R-squared scores:\")\n",
        "for score, feature in best_features:\n",
        "    print(f\"{feature}: {score}\")\n",
        "\n",
        "# Build the final model with the selected features\n",
        "selected_features = [feature for _, feature in best_features]\n",
        "X_train_selected = sm.add_constant(X_train[selected_features])\n",
        "X_test_selected = sm.add_constant(X_test[selected_features])\n",
        "final_model = sm.OLS(y_train, X_train_selected).fit()\n",
        "\n",
        "# Print the summary of the final model\n",
        "print(final_model.summary())\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred = final_model.predict(X_test_selected)\n",
        "print(f\"Test set R-squared: {final_model.rsquared}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "authorship_tag": "ABX9TyOiVGcosxpfUwFO8XC7wTJf",
      "gpuType": "V28",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
